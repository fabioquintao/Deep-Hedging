{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e9279e-55b6-407d-a439-8a7c007974c3",
   "metadata": {},
   "source": [
    "# Deep Hedging AI 4.0 Engine\n",
    "### Vanilla Deep Hedging engine reference implementation with dynamic training update.\n",
    "\n",
    "This is the main example notebook. It shows learning to hedge a vanilla call option (ATM by default), first in a Black & Scholes world with statistical drift, and secondly in a world where a second option can be traded.\n",
    "The examples are not intended to be overly realistic.\n",
    "\n",
    "In the Black & Scholes case we see that the hedge learned is _not_ the risk-neutral hedge. The notebook <tt>trainer-bs_nodrift.ipynb</tt> demonstrates that if the statistical drift is zero, and step size is sufficiently small (daily), then the Deep Hedging hedge approximates the risk-neutral hedge.\n",
    "\n",
    "### Hans Buehler, March 26 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d4e96d5-7016-4d65-97f6-e95f21df85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not on Sagemaker\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Slighly annoying: by default the SageMaker Python import directory does not include our git directory \"\"\"\n",
    "#!pip -q install cdxbasics \"tensorflow>=2.11\" \"tensorflow_probability==0.19\"\n",
    "import os\n",
    "p = os.getcwd()\n",
    "dhn = \"/deephedging/\"\n",
    "i = p.find(dhn)\n",
    "if i!=-1:\n",
    "    p = p[:i]\n",
    "    import sys\n",
    "    sys.path.append(p)\n",
    "    print(\"SageMaker: added python path %s\" % p)\n",
    "else:\n",
    "    print(\"Not on Sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861ef34b-392f-410d-9798-072ad8499019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Hedging AI says hello ... \n",
      "00: Initializing training for VanillaDeepHedging\n",
      "01:   VanillaDeepHedging: model generated. Preparing training for 12 epochs. Model has 909 trainable weights.\n",
      "02:     'VanillaDeepHedging is using a total of 909 weights: 431 for the main agent, 196 for 5 initial states and delta, and 282 weights for the two cvar@1 monetary utilities\n",
      "02:      Features available for the agent per time step:   action, cost, delta, ivol, lbnd_a, pnl, price, spot, sqrt_time_left, time_left and ubnd_a\n",
      "02:      Features used by the agent per time step:         delta, price and time_left\n",
      "02:      Features available for the initial agent:         cost, ivol, lbnd_a, price, spot, sqrt_time_left, time_left and ubnd_a\n",
      "02:      Features used by the initial agent:               price\n",
      "02:      Features available for the monetary utilities:    cost, ivol, lbnd_a, price, spot, sqrt_time_left, time_left and ubnd_a\n",
      "02:      Features used by the monetary utilities:          price\n",
      "02:     Number of time steps: 10\n",
      "02:     Trained VanillaDeepHedging until epoch 12/12 for 909 weights using 100 samples, 10 validation samples, batch size 32: trained all epochs | initial loss: 0.294289 (0.17877), best loss: 0.14006 (0.0629696). Best epoch 12. Last cached epoch 12 | memory used: rss 532.16796875, vms 508.96875 | time elapsed 19s; time per epoch 1s; estimated time remaining 0s | current time: 2023-04-16 09:55:27                                                     \n",
      "01:   VanillaDeepHedging status: trained all epochs. Current epoch: 12.\n",
      "01:    Weights set to best epoch: 12\n",
      "01:    State until epoch 12 cached into C:/Users/hansb/iCloudDrive/Python3/deephedging/v4/notebooks/.cache/VanillaDeepHedgingGym/0.0.1/batch_default/af4b2dd184bd358d38401bce6f08c3273c706ed9fc13597b.pck\n",
      "01:    Time: 2023-04-16 09:55:27\n",
      "00: Training VanillaDeepHedging completed 2023-04-16 09:55:28. Total training took 21s.\n",
      "=========================================\n",
      "Result keys\n",
      "dict_keys(['trn', 'val', 'display_name', 'progress_data', 'gym', 'start_time', 'end_time', 'epochs_trained', 'status', 'exception'])\n",
      "=========================================\n",
      "Config usage report\n",
      "config.gym.agent['activation'] = softplus # Activation function; default: relu\n",
      "config.gym.agent['depth'] = 3 # Depth; default: 3\n",
      "config.gym.agent['features'] = ['price', 'time_left', 'delta'] # Names of features to be used by this agent; default: ['price', 'time_left', 'delta']\n",
      "config.gym.agent['final_activation'] = linear # Final activation function; default: linear\n",
      "config.gym.agent['recurrence'] = 5 # Number of recurrent nodes; default: 5\n",
      "config.gym.agent['simple_regression'] = False # Learn simple regression model only; default: False\n",
      "config.gym.agent['width'] = 10 # Width; default: 50\n",
      "config.gym.agent['zero_model'] = True # Whether to initialze levels (but not derivatives) of the model with zero; default: True\n",
      "config.gym.environment['hard_clip'] = False # Use min/max instread of soft clip for limiting actions by their bounds; default: False\n",
      "config.gym.environment['outer_clip'] = True # Apply a hard clip 'outer_clip_cut_off' times the boundaries; default: True\n",
      "config.gym.environment['outer_clip_cut_off'] = 10.0 # Multiplier on bounds for outer_clip; default: 10.0\n",
      "config.gym.environment['softclip_hinge_softness'] = 1.0 # Specifies softness of bounding actions between lbnd_a and ubnd_a; default: 1.0\n",
      "config.gym.init_agent['activation'] = softplus # Activation function; default: relu\n",
      "config.gym.init_agent['depth'] = 2 # Depth; default: 3\n",
      "config.gym.init_agent['features'] = ['price'] # Names of features to be used by this agent; default: ['price']\n",
      "config.gym.init_agent['final_activation'] = linear # Final activation function; default: linear\n",
      "config.gym.init_agent['simple_regression'] = False # Learn simple regression model only; default: False\n",
      "config.gym.init_agent['width'] = 10 # Width; default: 25\n",
      "config.gym.init_agent['zero_model'] = True # Whether to initialze levels (but not derivatives) of the model with zero; default: True\n",
      "config.gym.objective['activation'] = softplus # Activation function; default: relu\n",
      "config.gym.objective['depth'] = 2 # Depth; default: 3\n",
      "config.gym.objective['features'] = ['price'] # Names of features to be used by this agent; default: ['price']\n",
      "config.gym.objective['final_activation'] = linear # Final activation function; default: linear\n",
      "config.gym.objective['lmbda'] = 1.0 # Risk aversion; default: 1.0\n",
      "config.gym.objective['simple_regression'] = False # Learn simple regression model only; default: False\n",
      "config.gym.objective['utility'] = cvar # Type of monetary utility; default: exp2\n",
      "config.gym.objective['width'] = 10 # Width; default: 25\n",
      "config.gym.objective['zero_model'] = True # Whether to initialze levels (but not derivatives) of the model with zero; default: True\n",
      "config.gym.tensorflow['seed'] = 423423423 # Set tensor random seed. Leave to None if not desired; default: 423423423\n",
      "config.gym['user_version'] = 0.0.1 # User-defined version of a gym. Changing this string will change the cache ID, and therefore will trigger a new calculation; default: 0.0.1\n",
      "config.trainer.caching['directory'] = ./.cache # Caching parent directory; default: ./.cache\n",
      "config.trainer.caching['epoch_freq'] = 10 # How often to cache results, in number of epochs; default: 10\n",
      "config.trainer.caching['mode'] = on # Caching strategy: 'on' for standard caching; 'gen' for caching but keep existing incompatible files; 'off' to turn off; 'update' to overwrite any existing cache; 'clear' to clear existing caches; 'readonly' to read existing caches but not write new ones; default: on\n",
      "config.trainer.caching['overwrite_file_name'] =  # Allows overwriting the full qualified filename of the object\n",
      "config.trainer.debug['check_numerics'] = False # Whether to check TF numerics; default: False\n",
      "config.trainer.debug['tf_verbose'] = 0 # Verbosity for TensorFlow fit(); default: 0\n",
      "config.trainer.train.optimizer['amsgrad'] = False # Parameter amsgrad for <class 'keras.optimizers.adam.Adam'>; default: False\n",
      "config.trainer.train.optimizer['beta_1'] = 0.9 # Parameter beta_1 for <class 'keras.optimizers.adam.Adam'>; default: 0.9\n",
      "config.trainer.train.optimizer['beta_2'] = 0.999 # Parameter beta_2 for <class 'keras.optimizers.adam.Adam'>; default: 0.999\n",
      "config.trainer.train.optimizer['clipnorm'] = None # Parameter clipnorm for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['clipvalue'] = 1.0 # Parameter clipvalue for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['ema_momentum'] = 0.99 # Parameter ema_momentum for <class 'keras.optimizers.adam.Adam'>; default: 0.99\n",
      "config.trainer.train.optimizer['ema_overwrite_frequency'] = None # Parameter ema_overwrite_frequency for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['epsilon'] = 1e-07 # Parameter epsilon for <class 'keras.optimizers.adam.Adam'>; default: 1e-07\n",
      "config.trainer.train.optimizer['global_clipnorm'] = 1.0 # Parameter global_clipnorm for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['jit_compile'] = True # Parameter jit_compile for <class 'keras.optimizers.adam.Adam'>; default: True\n",
      "config.trainer.train.optimizer['learning_rate'] = 0.001 # Parameter learning_rate for <class 'keras.optimizers.adam.Adam'>; default: 0.001\n",
      "config.trainer.train.optimizer['name'] = adam # Optimizer name. See https://www.tensorflow.org/api_docs/python/tf/keras/optimizers; default: adam\n",
      "config.trainer.train.optimizer['use_ema'] = False # Parameter use_ema for <class 'keras.optimizers.adam.Adam'>; default: False\n",
      "config.trainer.train.optimizer['weight_decay'] = None # Parameter weight_decay for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.tensor_board['hist_freq'] = 1 # Specify tensor board log frequency. See https://www.tensorflow.org/guide/profiler; default: 1\n",
      "config.trainer.train.tensor_board['log_dir'] =  # Specify tensor board log directory. See https://www.tensorflow.org/guide/profiler\n",
      "config.trainer.train.tensor_board['profile_batch'] = 0 # Batch used for profiling. Set to non-zero to activate profiling. See https://www.tensorflow.org/guide/profiler; default: 0\n",
      "config.trainer.train['batch_size'] = None # Batch size; default: None\n",
      "config.trainer.train['display_name'] = VanillaDeepHedging # Display name for this training run; default: VanillaDeepHedging\n",
      "config.trainer.train['epochs'] = 12 # Epochs; default: 100\n",
      "config.trainer.train['run_eagerly'] = False # Keras gym run_eagerly. Turn to True for debugging. This slows down training. Use None for default; default: False\n",
      "config.world['black_scholes'] = True # Hard overwrite to use a black & scholes model with vol 'rvol' and drift 'drift'. Also turns off the option as a tradable instrument by setting strike = 0; default: False\n",
      "config.world['corr_ms'] = 0.5 # Correlation between the asset and its mean; default: 0.5\n",
      "config.world['corr_vi'] = 0.8 # Correlation between the implied vol and the asset volatility; default: 0.8\n",
      "config.world['corr_vs'] = -0.7 # Correlation between the asset and its volatility; default: -0.7\n",
      "config.world['cost_p'] = 0.0005 # Trading cost for the option on top of delta and vega cost; default: 0.0005\n",
      "config.world['cost_s'] = 0.0002 # Trading cost spot; default: 0.0002\n",
      "config.world['cost_v'] = 0.02 # Trading cost vega; default: 0.02\n",
      "config.world['drift'] = 0.1 # Mean drift of the asset. This is the total drift; default: 0.1\n",
      "config.world['drift_vol'] = 0.1 # Vol of the drift; default: 0.1\n",
      "config.world['dt'] = 0.02 # Time per timestep; default: One week (1/50)\n",
      "config.world['invar_steps'] = 5 # Number of steps ahead to sample from invariant distribution; default: 5\n",
      "config.world['ivol'] = 0.2 # Initial implied volatility; default: Same as realized vol\n",
      "config.world['lbnd_as'] = -5.0 # Lower bound for the number of shares traded at each time step; default: -5.0\n",
      "config.world['lbnd_av'] = -5.0 # Lower bound for the number of options traded at each time step; default: -5.0\n",
      "config.world['meanrev_drift'] = 1.0 # Mean reversion of the drift of the asset; default: 1.0\n",
      "config.world['meanrev_ivol'] = 0.1 # Mean reversion for implied vol vol vs initial level; default: 0.1\n",
      "config.world['meanrev_rvol'] = 2.0 # Mean reversion for realized vol vs implied vol; default: 2.0\n",
      "config.world['no_stoch_drift'] = False # If true, turns off the stochastic drift of the asset, by setting meanrev_drift = 0. and drift_vol = 0; default: False\n",
      "config.world['no_stoch_vol'] = False # If true, turns off stochastic realized and implied vol, by setting meanrev_*vol = 0 and volvol_*vol = 0; default: False\n",
      "config.world['payoff'] = atmcall # Payoff function with parameter spots[samples,steps+1]. Can be a function which must return a vector [samples]. Can also be short 'atmcall' or short 'atmput', or a fixed numnber. The default is 'atmcall' which is a short call with strike 1: '- np.maximum( spots[:,-1] - 1, 0. )'. A short forward starting ATM call is given as '- np.maximum( spots[:,-1] - spots[:,0], 0. )'; default: atmcall\n",
      "config.world['rcorr_vs'] = -0.5 # Residual correlation between the asset and its implied volatility; default: -0.5\n",
      "config.world['rvol'] = 0.2 # Initial realized volatility; default: 0.2\n",
      "config.world['samples'] = 100 # Number of samples; default: 1000\n",
      "config.world['seed'] = 2312414312 # Random seed; default: 2312414312\n",
      "config.world['steps'] = 10 # Number of time steps; default: 10\n",
      "config.world['strike'] = 1.0 # Relative strike. Set to zero to turn off option; default: 1.0\n",
      "config.world['ttm_steps'] = 4 # Time to maturity of the option; in steps; default: 4\n",
      "config.world['ubnd_as'] = 5.0 # Upper bound for the number of shares traded at each time step; default: 5.0\n",
      "config.world['ubnd_av'] = 5.0 # Upper bound for the number of options traded at each time step; default: 5.0\n",
      "config.world['volvol_ivol'] = 0.5 # Vol of Vol for implied vol; default: 0.5\n",
      "config.world['volvol_rvol'] = 0.5 # Vol of Vol for realized vol; default: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Hedging AI says hello ... \")\n",
    "\n",
    "import importlib as imp\n",
    "import packages.cdx_tf.cdx_tf.util as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.gym as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.clip as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.optimizer as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.models as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.monetary_utility as _\n",
    "imp.reload(_)\n",
    "import deephedging.v4.gym as _\n",
    "imp.reload(_)\n",
    "import deephedging.v4.trainer as _\n",
    "imp.reload(_)\n",
    "\n",
    "from cdxbasics.config import Config\n",
    "from deephedging.v4.trainer import train2\n",
    "from deephedging.v4.gym import VanillaDeepHedgingGym\n",
    "from deephedging.v4.world import SimpleWorld_Spot_ATM\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# see print of the config below for numerous options\n",
    "config = Config()\n",
    "# world\n",
    "config.world.samples = 100\n",
    "config.world.black_scholes = True\n",
    "# gym\n",
    "config.gym.objective.utility = \"cvar\"\n",
    "config.gym.objective.lmbda = 1.\n",
    "config.gym.objective.depth = 2\n",
    "config.gym.objective.width = 10\n",
    "config.gym.objective.activation = \"softplus\"\n",
    "config.gym.agent.depth = 3\n",
    "config.gym.agent.width = 10\n",
    "config.gym.agent.activation = \"softplus\"\n",
    "config.gym.init_agent.depth = 2\n",
    "config.gym.init_agent.width = 10\n",
    "config.gym.init_agent.activation = \"softplus\"\n",
    "# trainer\n",
    "config.trainer.train.optimizer.name = \"adam\"\n",
    "config.trainer.train.optimizer.learning_rate = 0.001\n",
    "config.trainer.train.optimizer.clipvalue = 1.\n",
    "config.trainer.train.optimizer.global_clipnorm = 1.\n",
    "config.trainer.train.batch_size = None\n",
    "config.trainer.train.epochs = 12\n",
    "config.trainer.caching.mode = \"on\"\n",
    "\"\"\"\n",
    "config.trainer.visual.epoch_refresh = 5\n",
    "config.trainer.visual.confidence_pcnt_lo = 0.25\n",
    "config.trainer.visual.confidence_pcnt_hi = 0.75\n",
    "\"\"\"\n",
    "# create world\n",
    "world  = SimpleWorld_Spot_ATM( config.world )\n",
    "val_world  = world.clone(samples=world.nSamples//10)\n",
    "\n",
    "r = train2( world     = world,\n",
    "            val_world = val_world,\n",
    "            config    = config )\n",
    "\n",
    "# create training environment\n",
    "print(\"=========================================\")\n",
    "print(\"Result keys\")\n",
    "print(r.keys())\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"Config usage report\")\n",
    "print( config.usage_report() )\n",
    "config.done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
