{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e9279e-55b6-407d-a439-8a7c007974c3",
   "metadata": {},
   "source": [
    "# Deep Hedging AI 3.0 Engine\n",
    "### Vanilla Deep Hedging engine reference implementation with dynamic training update.\n",
    "\n",
    "This is the main example notebook. It shows learning to hedge a vanilla call option (ATM by default), first in a Black & Scholes world with statistical drift, and secondly in a world where a second option can be traded.\n",
    "The examples are not intended to be overly realistic.\n",
    "\n",
    "In the Black & Scholes case we see that the hedge learned is _not_ the risk-neutral hedge. The notebook <tt>trainer-bs_nodrift.ipynb</tt> demonstrates that if the statistical drift is zero, and step size is sufficiently small (daily), then the Deep Hedging hedge approximates the risk-neutral hedge.\n",
    "\n",
    "### Hans Buehler, March 26 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4e96d5-7016-4d65-97f6-e95f21df85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not on Sagemaker\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Slighly annoying: by default the SageMaker Python import directory does not include our git directory \"\"\"\n",
    "#!pip -q install cdxbasics \"tensorflow>=2.11\" \"tensorflow_probability==0.19\"\n",
    "import os\n",
    "p = os.getcwd()\n",
    "dhn = \"/deephedging/\"\n",
    "i = p.find(dhn)\n",
    "if i!=-1:\n",
    "    p = p[:i]\n",
    "    import sys\n",
    "    sys.path.append(p)\n",
    "    print(\"SageMaker: added python path %s\" % p)\n",
    "else:\n",
    "    print(\"Not on Sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "861ef34b-392f-410d-9798-072ad8499019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Hedging AI says hello ... \n",
      "01:   Initializing training for VanillaDeepHedging\n",
      "02:     VanillaDeepHedging: model generated. Preparing training for 12 epochs. Model has 909 trainable weights.\n",
      "03:       'VanillaDeepHedging is using a total of 909 weights: 431 for the main agent, 196 for 5 initial states and delta, and 282 weights for the two cvar@1 monetary utilities\n",
      "03:        Features available for the agent per time step:   _dimension_dummy, action, cost, delta, ivol, lbnd_a, pnl, price, spot, sqrt_time_left, time_left and ubnd_a\n",
      "03:        Features used by the agent per time step:         delta, price and time_left\n",
      "03:        Features available for the initial agent:         _dimension_dummy, cost, ivol, lbnd_a, price, spot, sqrt_time_left, time_left and ubnd_a\n",
      "03:        Features used by the initial agent:               price\n",
      "03:        Features available for the monetary utilities:    _dimension_dummy, cost, ivol, lbnd_a, price, spot, sqrt_time_left, time_left and ubnd_a\n",
      "03:        Features used by the monetary utilities:          price\n",
      "03:       Number of time steps: 10\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 1/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.283505, best loss: 0.283505. Best epoch 1. Last cached epoch 0 | memory used: rss 796.99609375, vms 780.1796875 | time elapsed 9s; time per epoch 9s; estimated time remaining 1:47 | current time: 2023-03-26 23:50:55, estimated end time: 2023-03-26 23:51:05\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 2/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.272926, best loss: 0.272926. Best epoch 2. Last cached epoch 0 | memory used: rss 797.046875, vms 780.1796875 | time elapsed 10s; time per epoch 5s; estimated time remaining 53s | current time: 2023-03-26 23:50:56, estimated end time: 2023-03-26 23:51:01\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 3/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.262446, best loss: 0.262446. Best epoch 3. Last cached epoch 0 | memory used: rss 797.10546875, vms 780.23828125 | time elapsed 11s; time per epoch 3s; estimated time remaining 34s | current time: 2023-03-26 23:50:57, estimated end time: 2023-03-26 23:51:01\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 4/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.251431, best loss: 0.251431. Best epoch 4. Last cached epoch 0 | memory used: rss 797.1796875, vms 780.23828125 | time elapsed 12s; time per epoch 3s; estimated time remaining 25s | current time: 2023-03-26 23:50:58, estimated end time: 2023-03-26 23:51:02\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 5/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.240956, best loss: 0.240956. Best epoch 5. Last cached epoch 0 | memory used: rss 797.1796875, vms 780.23828125 | time elapsed 14s; time per epoch 2s; estimated time remaining 19s | current time: 2023-03-26 23:50:59, estimated end time: 2023-03-26 23:51:02\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 6/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.23039, best loss: 0.23039. Best epoch 6. Last cached epoch 0 | memory used: rss 797.18359375, vms 780.23828125 | time elapsed 15s; time per epoch 2s; estimated time remaining 15s | current time: 2023-03-26 23:51:01, estimated end time: 2023-03-26 23:51:03\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 7/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.221136, best loss: 0.221136. Best epoch 7. Last cached epoch 0 | memory used: rss 797.19140625, vms 780.23828125 | time elapsed 16s; time per epoch 2s; estimated time remaining 11s | current time: 2023-03-26 23:51:02, estimated end time: 2023-03-26 23:51:04\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 8/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.21258, best loss: 0.21258. Best epoch 8. Last cached epoch 0 | memory used: rss 797.21875, vms 780.23828125 | time elapsed 17s; time per epoch 2s; estimated time remaining 8s | current time: 2023-03-26 23:51:03, estimated end time: 2023-03-26 23:51:05\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 9/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.204194, best loss: 0.204194. Best epoch 9. Last cached epoch 0 | memory used: rss 797.24609375, vms 780.23828125 | time elapsed 18s; time per epoch 2s; estimated time remaining 6s | current time: 2023-03-26 23:51:04, estimated end time: 2023-03-26 23:51:06\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 10/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.191963, best loss: 0.191963. Best epoch 10. Last cached epoch 0 | memory used: rss 797.26953125, vms 780.23828125 | time elapsed 19s; time per epoch 1s; estimated time remaining 3s | current time: 2023-03-26 23:51:05, estimated end time: 2023-03-26 23:51:07\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 11/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.183286, best loss: 0.183286. Best epoch 11. Last cached epoch 0 | memory used: rss 797.33203125, vms 780.23828125 | time elapsed 20s; time per epoch 1s; estimated time remaining 1s | current time: 2023-03-26 23:51:06, estimated end time: 2023-03-26 23:51:08\n",
      " 10 validation samples,\n",
      "03:       Training VanillaDeepHedging epoch 12/12 for 909 weights using 100 samples, 10 validation samples, batch size 32 | initial loss: 0.294289, current loss: 0.173956, best loss: 0.173956. Best epoch 12. Last cached epoch 0 | memory used: rss 797.33203125, vms 780.23828125 | time elapsed 21s; time per epoch 1s; estimated time remaining 0s | current time: 2023-03-26 23:51:06, estimated end time: 2023-03-26 23:51:08\n",
      "03:       Trained VanillaDeepHedging until epoch 12/12 for 909 weights using 100 samples, 10 validation samples, batch size 32: Trained all epochs | initial loss: 0.294289, best loss: 0.173956. Best epoch 12. Last cached epoch 0 | memory used: rss 797.33203125, vms 780.23828125 | time elapsed 21s; time per epoch 1s; estimated time remaining 0s | current time: 2023-03-26 23:51:07\n",
      "02:     VanillaDeepHedging status: Trained all epochs. Current epoch: 12.\n",
      "02:      Weights set to best epoch: 12\n",
      "02:      Time: 2023-03-26 23:51:07\n",
      "01:   Training VanillaDeepHedging completed 2023-03-26 23:51:08. Total training took 23s.\n",
      "=========================================\n",
      "Result\n",
      "{'trn': {'results': {'loss': array([0.02554345, 0.02554345, 0.02554345, 0.02554345, 0.02554345,\n",
      "       0.02554345, 0.02554345, 0.13580719, 0.02554345, 0.02554345,\n",
      "       0.06172635, 0.03906152, 0.02554345, 0.02554345, 0.03145204,\n",
      "       0.02554345, 0.02554345, 0.02554345, 0.02554345, 0.02554345,\n",
      "       0.02554345, 0.02554345, 0.02554345, 0.02554345, 0.02554345,\n",
      "       0.02554345, 0.03741121, 0.17944305, 0.07748129, 0.02554345,\n",
      "       0.02554345, 0.02554345, 0.02554345, 0.02554345, 0.02554345,\n",
      "       0.02554345, 0.02554345, 0.02554345, 0.02554345, 0.07660127,\n",
      "       0.02554345, 0.11323225, 0.02554345, 0.02554345, 0.02554345,\n",
      "       0.02554345, 0.02554345, 0.03211848, 0.0280149 , 0.02987099,\n",
      "       0.04107067, 0.03554288, 0.0427835 , 0.04922193, 0.05097628,\n",
      "       0.12968436, 0.0685482 , 0.23057733, 0.07992546, 0.1701935 ,\n",
      "       0.07685804, 0.08058333, 0.08324838, 0.08652472, 0.08736086,\n",
      "       0.12268016, 0.17027944, 0.09619141, 0.13665393, 0.18271288,\n",
      "       0.15752271, 0.21534836, 0.11419415, 0.12090445, 0.29502633,\n",
      "       0.2508549 , 0.311789  , 0.14023256, 0.14218307, 0.15180159,\n",
      "       0.1541462 , 0.18264922, 0.4201791 , 0.6303316 , 0.28058136,\n",
      "       0.34501374, 0.35726   , 0.38048828, 0.4341625 , 0.526808  ,\n",
      "       0.6315915 , 0.54083943, 0.72890556, 0.47214836, 0.59241295,\n",
      "       0.8353732 , 0.8926235 , 0.8527275 , 1.1801009 , 1.222894  ],\n",
      "      dtype=float32), 'utility': array([-0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.02513015, -0.02513015, -0.13539389, -0.02513015, -0.02513015,\n",
      "       -0.06131306, -0.03864822, -0.02513015, -0.02513015, -0.03103875,\n",
      "       -0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.02513015, -0.03699791, -0.17902975, -0.07706799, -0.02513015,\n",
      "       -0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.07618798,\n",
      "       -0.02513015, -0.11281896, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.02513015, -0.02513015, -0.03009133, -0.02513015, -0.02513015,\n",
      "       -0.03581962, -0.03022149, -0.02513015, -0.03119189, -0.02513015,\n",
      "       -0.089206  , -0.02513015, -0.18161081, -0.02935104, -0.11948389,\n",
      "       -0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.05880722, -0.10028797, -0.02513015, -0.06123868, -0.10449669,\n",
      "       -0.07615701, -0.1275034 , -0.02513015, -0.02513015, -0.19413748,\n",
      "       -0.14925845, -0.20778283, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.02513015, -0.03451774, -0.26677856, -0.45278543, -0.1014085 ,\n",
      "       -0.15562989, -0.16768704, -0.17944147, -0.23111272, -0.30312192,\n",
      "       -0.37180978, -0.27351296, -0.42562696, -0.16186817, -0.26167905,\n",
      "       -0.4821946 , -0.5195622 , -0.46942562, -0.6042294 , -0.5660892 ],\n",
      "      dtype=float32), 'utility0': array([-4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -4.13298607e-04,\n",
      "       -4.13298607e-04, -4.13298607e-04, -4.13298607e-04, -2.02715397e-03,\n",
      "       -2.88474560e-03, -4.74083424e-03, -5.25105000e-03, -5.32138348e-03,\n",
      "       -1.76533461e-02, -1.80300474e-02, -2.58461237e-02, -4.04783487e-02,\n",
      "       -4.34180498e-02, -4.89665270e-02, -5.05744219e-02, -5.07096052e-02,\n",
      "       -5.17278910e-02, -5.54531813e-02, -5.81182241e-02, -6.13945723e-02,\n",
      "       -6.22307062e-02, -6.38729334e-02, -6.99914694e-02, -7.10612535e-02,\n",
      "       -7.54152536e-02, -7.82161951e-02, -8.13657045e-02, -8.78449678e-02,\n",
      "       -8.90640020e-02, -9.57742929e-02, -1.00888848e-01, -1.01596475e-01,\n",
      "       -1.04006171e-01, -1.15102410e-01, -1.17052913e-01, -1.26671433e-01,\n",
      "       -1.29016042e-01, -1.48131490e-01, -1.53400540e-01, -1.77546144e-01,\n",
      "       -1.79172873e-01, -1.89383864e-01, -1.89572930e-01, -2.01046824e-01,\n",
      "       -2.03049779e-01, -2.23686099e-01, -2.59781718e-01, -2.67326474e-01,\n",
      "       -3.03278565e-01, -3.10280204e-01, -3.30733895e-01, -3.53178620e-01,\n",
      "       -3.73061299e-01, -3.83301854e-01, -5.75871587e-01, -6.56804681e-01],\n",
      "      dtype=float32), 'gains': array([ 0.02003254, -0.02172034,  0.09367865,  0.00920162,  0.04332427,\n",
      "       -0.01343806,  0.01098743, -0.08026202,  0.02023182,  0.04146739,\n",
      "       -0.0432216 , -0.03188919,  0.04594593,  0.00339673, -0.02808445,\n",
      "       -0.0075808 , -0.02060148,  0.05486578, -0.01212617, -0.0106924 ,\n",
      "       -0.0141735 ,  0.01058108, -0.02502676,  0.02031423,  0.01439391,\n",
      "       -0.00168978, -0.03106403, -0.10207995, -0.05109907,  0.06877427,\n",
      "        0.06175456,  0.06957156,  0.02547056,  0.16270664,  0.05808487,\n",
      "       -0.0239495 ,  0.03667747, -0.01814204, -0.00076617, -0.05065906,\n",
      "        0.00041889, -0.06897455,  0.01439131,  0.08243175,  0.03816954,\n",
      "        0.06795713, -0.01703083, -0.02761074,  0.00530513, -0.02329242,\n",
      "       -0.03047488, -0.02767582,  0.00430353, -0.02816102,  0.02804118,\n",
      "       -0.05716808,  0.01903296, -0.10337048, -0.0272406 , -0.07230702,\n",
      "        0.04347437, -0.01703026,  0.02187209,  0.0699207 ,  0.01935755,\n",
      "       -0.04196869, -0.06270906,  0.01688662, -0.04318442, -0.06481342,\n",
      "       -0.05064358, -0.07631677,  0.03572537, -0.02155091, -0.10963382,\n",
      "       -0.0871943 , -0.11645649,  0.0247518 ,  0.00180122, -0.02194727,\n",
      "       -0.01165569, -0.02982395, -0.14595436, -0.23895779, -0.06326932,\n",
      "       -0.09038002, -0.0964086 , -0.10228581, -0.12812144, -0.16412604,\n",
      "       -0.19846997, -0.14932156, -0.22537856, -0.09349916, -0.1434046 ,\n",
      "       -0.25366238, -0.27234617, -0.24727789, -0.31467977, -0.29560968],\n",
      "      dtype=float32), 'payoff': array([-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.00080693, -0.00123572, -0.00216377,\n",
      "       -0.00241888, -0.00245404, -0.00862002, -0.00880837, -0.01271641,\n",
      "       -0.02003253, -0.02150238, -0.02427661, -0.02508056, -0.02514815,\n",
      "       -0.0256573 , -0.02751994, -0.02885246, -0.03049064, -0.0309087 ,\n",
      "       -0.03172982, -0.03478909, -0.03532398, -0.03750098, -0.03890145,\n",
      "       -0.0404762 , -0.04371583, -0.04432535, -0.0476805 , -0.05023777,\n",
      "       -0.05059159, -0.05179644, -0.05734456, -0.05831981, -0.06312907,\n",
      "       -0.06430137, -0.0738591 , -0.07649362, -0.08856642, -0.08937979,\n",
      "       -0.09448528, -0.09457982, -0.10031676, -0.10131824, -0.1116364 ,\n",
      "       -0.12968421, -0.13345659, -0.15143263, -0.15493345, -0.1651603 ,\n",
      "       -0.17638266, -0.186324  , -0.19144428, -0.28772914, -0.3281957 ],\n",
      "      dtype=float32), 'pnl': array([ 0.02046344, -0.02128492,  0.09413979,  0.00965279,  0.04378235,\n",
      "       -0.01298929,  0.01144107, -0.07982612,  0.02068778,  0.04192974,\n",
      "       -0.0427753 , -0.03143935,  0.04641134,  0.00385507, -0.02763219,\n",
      "       -0.00712417, -0.02014714,  0.05533613, -0.01166863, -0.01023394,\n",
      "       -0.01371464,  0.01104526, -0.02456925,  0.02078155,  0.01486045,\n",
      "       -0.00122614, -0.03060472, -0.10163377, -0.05064294,  0.06925396,\n",
      "        0.06223339,  0.07005231,  0.02594278,  0.16320571,  0.0585637 ,\n",
      "       -0.02348602,  0.03715282, -0.01767538, -0.00029583, -0.05019832,\n",
      "        0.00088997, -0.0685167 ,  0.01486657,  0.08292019,  0.03865092,\n",
      "        0.0684443 , -0.01655959, -0.02633398,  0.0070172 , -0.0206575 ,\n",
      "       -0.02758618, -0.02475136,  0.01340242, -0.01887999,  0.04124254,\n",
      "       -0.03666435,  0.04102181, -0.07863002, -0.00168118, -0.04668872,\n",
      "        0.06962439,  0.01097137,  0.05121427,  0.100911  ,  0.05075627,\n",
      "       -0.00976043, -0.02744437,  0.05270175, -0.00520308, -0.02543529,\n",
      "       -0.00968737, -0.03212468,  0.08054879,  0.02661786, -0.05892381,\n",
      "       -0.03612604, -0.0641886 ,  0.08259715,  0.06061776,  0.04167569,\n",
      "        0.05314197,  0.04453145, -0.06898589, -0.14992999,  0.02660607,\n",
      "        0.00459747, -0.00133768, -0.00147701, -0.0263157 , -0.05200529,\n",
      "       -0.06830138, -0.01536973, -0.07345878,  0.06194811,  0.02226367,\n",
      "       -0.07678887, -0.0855313 , -0.05533604, -0.02643078,  0.03312422],\n",
      "      dtype=float32), 'cost': array([0.0004309 , 0.00043542, 0.00046115, 0.00045117, 0.00045809,\n",
      "       0.00044877, 0.00045364, 0.0004359 , 0.00045596, 0.00046235,\n",
      "       0.0004463 , 0.00044984, 0.00046541, 0.00045834, 0.00045226,\n",
      "       0.00045662, 0.00045434, 0.00047035, 0.00045755, 0.00045846,\n",
      "       0.00045886, 0.00046418, 0.00045751, 0.00046732, 0.00046654,\n",
      "       0.00046365, 0.00045931, 0.00044618, 0.00045614, 0.00047969,\n",
      "       0.00047883, 0.00048075, 0.00047222, 0.00049907, 0.00047883,\n",
      "       0.00046348, 0.00047535, 0.00046666, 0.00047034, 0.00046074,\n",
      "       0.00047108, 0.00045786, 0.00047526, 0.00048844, 0.00048138,\n",
      "       0.00048716, 0.00047123, 0.00046983, 0.00047634, 0.00047114,\n",
      "       0.00046983, 0.00047042, 0.00047887, 0.00047265, 0.00048495,\n",
      "       0.0004712 , 0.00048648, 0.00046384, 0.00047885, 0.00047014,\n",
      "       0.00049273, 0.00048169, 0.00048972, 0.00049966, 0.00049001,\n",
      "       0.00047844, 0.00047561, 0.00049115, 0.00048036, 0.00047668,\n",
      "       0.00048001, 0.00047625, 0.00049807, 0.00048827, 0.00047223,\n",
      "       0.00047667, 0.00047146, 0.00050079, 0.00049673, 0.00049389,\n",
      "       0.00049629, 0.0004963 , 0.00047486, 0.00046139, 0.0004956 ,\n",
      "       0.00049221, 0.00049109, 0.00049204, 0.00048749, 0.00048434,\n",
      "       0.00048438, 0.00049523, 0.00048713, 0.00051381, 0.00050798,\n",
      "       0.00049085, 0.00049088, 0.00049759, 0.00051984, 0.00053821],\n",
      "      dtype=float32), 'actions': array([[[ 0.7306366 ],\n",
      "        [-0.1837492 ],\n",
      "        [-0.18437338],\n",
      "        [-0.18474674],\n",
      "        [-0.18465567],\n",
      "        [-0.18400478],\n",
      "        [-0.18328667],\n",
      "        [-0.18261147],\n",
      "        [-0.18208742],\n",
      "        [-0.18111277]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18386602],\n",
      "        [-0.18444252],\n",
      "        [-0.1846714 ],\n",
      "        [-0.18459749],\n",
      "        [-0.1840663 ],\n",
      "        [-0.18349648],\n",
      "        [-0.18253231],\n",
      "        [-0.18148327],\n",
      "        [-0.18057251]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18380642],\n",
      "        [-0.1842022 ],\n",
      "        [-0.18422651],\n",
      "        [-0.18389225],\n",
      "        [-0.18349743],\n",
      "        [-0.18262482],\n",
      "        [-0.18173265],\n",
      "        [-0.18111038],\n",
      "        [-0.18044233]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18344164],\n",
      "        [-0.1840868 ],\n",
      "        [-0.18418264],\n",
      "        [-0.184309  ],\n",
      "        [-0.18392992],\n",
      "        [-0.18325901],\n",
      "        [-0.18242836],\n",
      "        [-0.18142462],\n",
      "        [-0.18021345]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18351078],\n",
      "        [-0.18412209],\n",
      "        [-0.18425703],\n",
      "        [-0.18407154],\n",
      "        [-0.18361378],\n",
      "        [-0.18293095],\n",
      "        [-0.1821909 ],\n",
      "        [-0.18116093],\n",
      "        [-0.1802392 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18346405],\n",
      "        [-0.18414783],\n",
      "        [-0.18432093],\n",
      "        [-0.18426466],\n",
      "        [-0.18402576],\n",
      "        [-0.18317318],\n",
      "        [-0.18241882],\n",
      "        [-0.18141985],\n",
      "        [-0.1804471 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18351555],\n",
      "        [-0.18421459],\n",
      "        [-0.18419695],\n",
      "        [-0.18424225],\n",
      "        [-0.18387079],\n",
      "        [-0.18314362],\n",
      "        [-0.18226528],\n",
      "        [-0.18117046],\n",
      "        [-0.18018293]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18380356],\n",
      "        [-0.18444729],\n",
      "        [-0.18463898],\n",
      "        [-0.18459797],\n",
      "        [-0.18415499],\n",
      "        [-0.18349123],\n",
      "        [-0.18266678],\n",
      "        [-0.181458  ],\n",
      "        [-0.18036604]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18358469],\n",
      "        [-0.18416452],\n",
      "        [-0.18440008],\n",
      "        [-0.18411446],\n",
      "        [-0.18355799],\n",
      "        [-0.18283844],\n",
      "        [-0.182127  ],\n",
      "        [-0.18130684],\n",
      "        [-0.1803503 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18344784],\n",
      "        [-0.18391609],\n",
      "        [-0.18440962],\n",
      "        [-0.18408108],\n",
      "        [-0.18366337],\n",
      "        [-0.18275213],\n",
      "        [-0.1819334 ],\n",
      "        [-0.18110704],\n",
      "        [-0.18003178]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18359089],\n",
      "        [-0.18433952],\n",
      "        [-0.18454981],\n",
      "        [-0.18448544],\n",
      "        [-0.1840024 ],\n",
      "        [-0.1832552 ],\n",
      "        [-0.18219042],\n",
      "        [-0.18134165],\n",
      "        [-0.18016815]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18354607],\n",
      "        [-0.18433857],\n",
      "        [-0.18470287],\n",
      "        [-0.18448925],\n",
      "        [-0.18388796],\n",
      "        [-0.1829958 ],\n",
      "        [-0.18216658],\n",
      "        [-0.18110228],\n",
      "        [-0.18004656]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18339586],\n",
      "        [-0.18381548],\n",
      "        [-0.18405724],\n",
      "        [-0.18401337],\n",
      "        [-0.18358135],\n",
      "        [-0.18286943],\n",
      "        [-0.18212414],\n",
      "        [-0.18107176],\n",
      "        [-0.1799779 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18345928],\n",
      "        [-0.18395805],\n",
      "        [-0.1841507 ],\n",
      "        [-0.18403435],\n",
      "        [-0.18357372],\n",
      "        [-0.18316936],\n",
      "        [-0.18245888],\n",
      "        [-0.18130112],\n",
      "        [-0.1799841 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18363714],\n",
      "        [-0.18413258],\n",
      "        [-0.18468857],\n",
      "        [-0.18416214],\n",
      "        [-0.18381882],\n",
      "        [-0.18313599],\n",
      "        [-0.18220854],\n",
      "        [-0.18113613],\n",
      "        [-0.18001175]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18361521],\n",
      "        [-0.18428278],\n",
      "        [-0.1843195 ],\n",
      "        [-0.18423462],\n",
      "        [-0.1836729 ],\n",
      "        [-0.18311024],\n",
      "        [-0.18204975],\n",
      "        [-0.18093634],\n",
      "        [-0.17997646]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18339825],\n",
      "        [-0.18393946],\n",
      "        [-0.18435383],\n",
      "        [-0.1842413 ],\n",
      "        [-0.18367767],\n",
      "        [-0.18305063],\n",
      "        [-0.18238497],\n",
      "        [-0.18149471],\n",
      "        [-0.1802454 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18339062],\n",
      "        [-0.18380451],\n",
      "        [-0.184021  ],\n",
      "        [-0.18390656],\n",
      "        [-0.18324661],\n",
      "        [-0.18252563],\n",
      "        [-0.1818819 ],\n",
      "        [-0.18120241],\n",
      "        [-0.18014383]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1835165 ],\n",
      "        [-0.18388462],\n",
      "        [-0.18403435],\n",
      "        [-0.18403769],\n",
      "        [-0.18380928],\n",
      "        [-0.18307686],\n",
      "        [-0.18252754],\n",
      "        [-0.18115139],\n",
      "        [-0.18021345]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18372965],\n",
      "        [-0.18404102],\n",
      "        [-0.1841836 ],\n",
      "        [-0.18405628],\n",
      "        [-0.1837945 ],\n",
      "        [-0.18308878],\n",
      "        [-0.18217182],\n",
      "        [-0.18098736],\n",
      "        [-0.17987776]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18332243],\n",
      "        [-0.18397903],\n",
      "        [-0.1840477 ],\n",
      "        [-0.18381357],\n",
      "        [-0.18342876],\n",
      "        [-0.18324375],\n",
      "        [-0.18242884],\n",
      "        [-0.18164158],\n",
      "        [-0.1802206 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18342876],\n",
      "        [-0.18382835],\n",
      "        [-0.18414068],\n",
      "        [-0.1839571 ],\n",
      "        [-0.18357944],\n",
      "        [-0.18300962],\n",
      "        [-0.18206024],\n",
      "        [-0.18117142],\n",
      "        [-0.17992306]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18373775],\n",
      "        [-0.18404531],\n",
      "        [-0.18434763],\n",
      "        [-0.18413973],\n",
      "        [-0.18367672],\n",
      "        [-0.182765  ],\n",
      "        [-0.18208504],\n",
      "        [-0.18120861],\n",
      "        [-0.18011999]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18367767],\n",
      "        [-0.18405724],\n",
      "        [-0.18407774],\n",
      "        [-0.18431568],\n",
      "        [-0.18366098],\n",
      "        [-0.18258953],\n",
      "        [-0.18160391],\n",
      "        [-0.18050623],\n",
      "        [-0.17984581]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18344593],\n",
      "        [-0.18400478],\n",
      "        [-0.1840229 ],\n",
      "        [-0.18378782],\n",
      "        [-0.1834631 ],\n",
      "        [-0.1829691 ],\n",
      "        [-0.1820283 ],\n",
      "        [-0.18110943],\n",
      "        [-0.17985344]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18361616],\n",
      "        [-0.18400383],\n",
      "        [-0.18426466],\n",
      "        [-0.18408537],\n",
      "        [-0.18374252],\n",
      "        [-0.18265057],\n",
      "        [-0.18203449],\n",
      "        [-0.18091965],\n",
      "        [-0.17970753]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18353891],\n",
      "        [-0.18411684],\n",
      "        [-0.18432808],\n",
      "        [-0.18389416],\n",
      "        [-0.18355894],\n",
      "        [-0.18313599],\n",
      "        [-0.18209362],\n",
      "        [-0.1811099 ],\n",
      "        [-0.1800828 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18368816],\n",
      "        [-0.18441486],\n",
      "        [-0.18480492],\n",
      "        [-0.18457031],\n",
      "        [-0.18396187],\n",
      "        [-0.18315315],\n",
      "        [-0.1821351 ],\n",
      "        [-0.18108654],\n",
      "        [-0.17998743]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18351936],\n",
      "        [-0.1842618 ],\n",
      "        [-0.18440962],\n",
      "        [-0.18414259],\n",
      "        [-0.18343496],\n",
      "        [-0.18289614],\n",
      "        [-0.182405  ],\n",
      "        [-0.18106413],\n",
      "        [-0.18025017]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18321228],\n",
      "        [-0.1835413 ],\n",
      "        [-0.1837902 ],\n",
      "        [-0.1837449 ],\n",
      "        [-0.18338919],\n",
      "        [-0.18244314],\n",
      "        [-0.1818366 ],\n",
      "        [-0.18087387],\n",
      "        [-0.1796856 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18342257],\n",
      "        [-0.18361092],\n",
      "        [-0.18374634],\n",
      "        [-0.18343496],\n",
      "        [-0.18333626],\n",
      "        [-0.18276787],\n",
      "        [-0.18156528],\n",
      "        [-0.1809063 ],\n",
      "        [-0.17988443]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1832242 ],\n",
      "        [-0.18365383],\n",
      "        [-0.1839714 ],\n",
      "        [-0.18366623],\n",
      "        [-0.18326473],\n",
      "        [-0.18257189],\n",
      "        [-0.18166924],\n",
      "        [-0.18062782],\n",
      "        [-0.17960835]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18347645],\n",
      "        [-0.18393087],\n",
      "        [-0.18403292],\n",
      "        [-0.18385506],\n",
      "        [-0.18327999],\n",
      "        [-0.18273306],\n",
      "        [-0.18167305],\n",
      "        [-0.18095303],\n",
      "        [-0.17973232]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1832161 ],\n",
      "        [-0.18353176],\n",
      "        [-0.18367767],\n",
      "        [-0.18316555],\n",
      "        [-0.18257856],\n",
      "        [-0.18199635],\n",
      "        [-0.1812625 ],\n",
      "        [-0.18011856],\n",
      "        [-0.17954159]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18357325],\n",
      "        [-0.18388033],\n",
      "        [-0.18377686],\n",
      "        [-0.18348885],\n",
      "        [-0.18319178],\n",
      "        [-0.18240213],\n",
      "        [-0.18170118],\n",
      "        [-0.18083858],\n",
      "        [-0.17972183]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18365622],\n",
      "        [-0.18443346],\n",
      "        [-0.18461657],\n",
      "        [-0.18400764],\n",
      "        [-0.1833396 ],\n",
      "        [-0.18264818],\n",
      "        [-0.18170881],\n",
      "        [-0.18075228],\n",
      "        [-0.17974758]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18351078],\n",
      "        [-0.1836276 ],\n",
      "        [-0.18377113],\n",
      "        [-0.18361759],\n",
      "        [-0.18336678],\n",
      "        [-0.18296671],\n",
      "        [-0.1818533 ],\n",
      "        [-0.18083382],\n",
      "        [-0.17965555]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18360233],\n",
      "        [-0.18426323],\n",
      "        [-0.1843481 ],\n",
      "        [-0.18399954],\n",
      "        [-0.18336582],\n",
      "        [-0.18285751],\n",
      "        [-0.18159819],\n",
      "        [-0.1807003 ],\n",
      "        [-0.17969704]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18334913],\n",
      "        [-0.18392563],\n",
      "        [-0.18412018],\n",
      "        [-0.18403244],\n",
      "        [-0.18353176],\n",
      "        [-0.18276024],\n",
      "        [-0.18190098],\n",
      "        [-0.1805954 ],\n",
      "        [-0.17972946]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18360662],\n",
      "        [-0.18399191],\n",
      "        [-0.18449736],\n",
      "        [-0.18442822],\n",
      "        [-0.18377209],\n",
      "        [-0.1828742 ],\n",
      "        [-0.18183899],\n",
      "        [-0.1807313 ],\n",
      "        [-0.17966509]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1835928 ],\n",
      "        [-0.18401337],\n",
      "        [-0.18412638],\n",
      "        [-0.18391562],\n",
      "        [-0.18342495],\n",
      "        [-0.1827507 ],\n",
      "        [-0.18161249],\n",
      "        [-0.18056011],\n",
      "        [-0.17976189]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1836214 ],\n",
      "        [-0.18422556],\n",
      "        [-0.18454075],\n",
      "        [-0.18442726],\n",
      "        [-0.18376446],\n",
      "        [-0.18302155],\n",
      "        [-0.18183613],\n",
      "        [-0.18069792],\n",
      "        [-0.17971468]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18352222],\n",
      "        [-0.18394375],\n",
      "        [-0.18410158],\n",
      "        [-0.18378639],\n",
      "        [-0.18322372],\n",
      "        [-0.18246078],\n",
      "        [-0.18174458],\n",
      "        [-0.18063164],\n",
      "        [-0.17968082]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18332243],\n",
      "        [-0.1837883 ],\n",
      "        [-0.18388987],\n",
      "        [-0.18324852],\n",
      "        [-0.18304586],\n",
      "        [-0.1821804 ],\n",
      "        [-0.18148851],\n",
      "        [-0.1804514 ],\n",
      "        [-0.17946911]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18334913],\n",
      "        [-0.18395805],\n",
      "        [-0.18401194],\n",
      "        [-0.18384504],\n",
      "        [-0.18309641],\n",
      "        [-0.1823721 ],\n",
      "        [-0.18126011],\n",
      "        [-0.18038273],\n",
      "        [-0.1797533 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1834197 ],\n",
      "        [-0.1838131 ],\n",
      "        [-0.18394089],\n",
      "        [-0.18343735],\n",
      "        [-0.18300104],\n",
      "        [-0.18245268],\n",
      "        [-0.1812129 ],\n",
      "        [-0.18042278],\n",
      "        [-0.17932129]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1833682 ],\n",
      "        [-0.18381882],\n",
      "        [-0.18403816],\n",
      "        [-0.18379307],\n",
      "        [-0.18353271],\n",
      "        [-0.18277216],\n",
      "        [-0.18206692],\n",
      "        [-0.18066597],\n",
      "        [-0.17980862]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18342686],\n",
      "        [-0.18384981],\n",
      "        [-0.18386173],\n",
      "        [-0.1839056 ],\n",
      "        [-0.18353176],\n",
      "        [-0.1829505 ],\n",
      "        [-0.18196058],\n",
      "        [-0.18085909],\n",
      "        [-0.17976952]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18364143],\n",
      "        [-0.18388748],\n",
      "        [-0.18390751],\n",
      "        [-0.18372536],\n",
      "        [-0.18308878],\n",
      "        [-0.18246174],\n",
      "        [-0.18191147],\n",
      "        [-0.18086147],\n",
      "        [-0.17943954]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18347692],\n",
      "        [-0.18399239],\n",
      "        [-0.18401337],\n",
      "        [-0.18405008],\n",
      "        [-0.18345928],\n",
      "        [-0.18279552],\n",
      "        [-0.18165827],\n",
      "        [-0.18073034],\n",
      "        [-0.17958927]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18355322],\n",
      "        [-0.18407154],\n",
      "        [-0.18444729],\n",
      "        [-0.18391418],\n",
      "        [-0.18333626],\n",
      "        [-0.18279171],\n",
      "        [-0.18165493],\n",
      "        [-0.18056822],\n",
      "        [-0.17955399]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18344212],\n",
      "        [-0.184021  ],\n",
      "        [-0.18408203],\n",
      "        [-0.18392038],\n",
      "        [-0.18327045],\n",
      "        [-0.18270254],\n",
      "        [-0.18180418],\n",
      "        [-0.18088722],\n",
      "        [-0.17984438]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18372059],\n",
      "        [-0.18377209],\n",
      "        [-0.18397522],\n",
      "        [-0.18381023],\n",
      "        [-0.18311548],\n",
      "        [-0.18235302],\n",
      "        [-0.18169641],\n",
      "        [-0.1805253 ],\n",
      "        [-0.17945957]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18348503],\n",
      "        [-0.1840024 ],\n",
      "        [-0.18423748],\n",
      "        [-0.18376589],\n",
      "        [-0.1835413 ],\n",
      "        [-0.18262625],\n",
      "        [-0.18179846],\n",
      "        [-0.18059444],\n",
      "        [-0.1794033 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18343401],\n",
      "        [-0.18395662],\n",
      "        [-0.1841116 ],\n",
      "        [-0.18371487],\n",
      "        [-0.18289804],\n",
      "        [-0.18233109],\n",
      "        [-0.18141985],\n",
      "        [-0.18022346],\n",
      "        [-0.17920971]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18350983],\n",
      "        [-0.18397379],\n",
      "        [-0.18426323],\n",
      "        [-0.1838007 ],\n",
      "        [-0.18344879],\n",
      "        [-0.18268871],\n",
      "        [-0.18163109],\n",
      "        [-0.18084621],\n",
      "        [-0.17959309]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1833868 ],\n",
      "        [-0.18381977],\n",
      "        [-0.1838808 ],\n",
      "        [-0.18355417],\n",
      "        [-0.18291712],\n",
      "        [-0.18236685],\n",
      "        [-0.18146896],\n",
      "        [-0.18046284],\n",
      "        [-0.17930698]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18369865],\n",
      "        [-0.18400955],\n",
      "        [-0.1841836 ],\n",
      "        [-0.18406343],\n",
      "        [-0.18369007],\n",
      "        [-0.18265438],\n",
      "        [-0.18184233],\n",
      "        [-0.1810832 ],\n",
      "        [-0.17978716]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18329144],\n",
      "        [-0.18397903],\n",
      "        [-0.1840949 ],\n",
      "        [-0.18390465],\n",
      "        [-0.18325281],\n",
      "        [-0.18235016],\n",
      "        [-0.18160057],\n",
      "        [-0.18063307],\n",
      "        [-0.17931986]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18327475],\n",
      "        [-0.18407154],\n",
      "        [-0.18441677],\n",
      "        [-0.18424273],\n",
      "        [-0.18349409],\n",
      "        [-0.18285227],\n",
      "        [-0.18158913],\n",
      "        [-0.18048859],\n",
      "        [-0.17937231]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1833129 ],\n",
      "        [-0.18375444],\n",
      "        [-0.1836729 ],\n",
      "        [-0.18352127],\n",
      "        [-0.1827836 ],\n",
      "        [-0.18223238],\n",
      "        [-0.18145609],\n",
      "        [-0.18025303],\n",
      "        [-0.17908144]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18369722],\n",
      "        [-0.18424082],\n",
      "        [-0.1840601 ],\n",
      "        [-0.18365574],\n",
      "        [-0.18297148],\n",
      "        [-0.18229723],\n",
      "        [-0.18130827],\n",
      "        [-0.18034029],\n",
      "        [-0.17919779]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18356991],\n",
      "        [-0.18377542],\n",
      "        [-0.18392801],\n",
      "        [-0.18372011],\n",
      "        [-0.18275833],\n",
      "        [-0.18214417],\n",
      "        [-0.18121815],\n",
      "        [-0.18016577],\n",
      "        [-0.17920113]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1831255 ],\n",
      "        [-0.18333006],\n",
      "        [-0.18346405],\n",
      "        [-0.18345165],\n",
      "        [-0.1825862 ],\n",
      "        [-0.18207121],\n",
      "        [-0.18123627],\n",
      "        [-0.1802826 ],\n",
      "        [-0.17950249]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18336058],\n",
      "        [-0.18369675],\n",
      "        [-0.18377876],\n",
      "        [-0.18345404],\n",
      "        [-0.18312836],\n",
      "        [-0.18218803],\n",
      "        [-0.18140078],\n",
      "        [-0.18032598],\n",
      "        [-0.17921686]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18359375],\n",
      "        [-0.18408012],\n",
      "        [-0.18403053],\n",
      "        [-0.18383884],\n",
      "        [-0.18331146],\n",
      "        [-0.18249893],\n",
      "        [-0.18132496],\n",
      "        [-0.18048191],\n",
      "        [-0.17922497]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1833272 ],\n",
      "        [-0.18372965],\n",
      "        [-0.18400383],\n",
      "        [-0.18387079],\n",
      "        [-0.18339205],\n",
      "        [-0.18277454],\n",
      "        [-0.18175602],\n",
      "        [-0.18061352],\n",
      "        [-0.17962456]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18336964],\n",
      "        [-0.18356419],\n",
      "        [-0.18376923],\n",
      "        [-0.1837511 ],\n",
      "        [-0.18315077],\n",
      "        [-0.1822877 ],\n",
      "        [-0.18112946],\n",
      "        [-0.18013477],\n",
      "        [-0.17913055]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18323135],\n",
      "        [-0.18382502],\n",
      "        [-0.1842022 ],\n",
      "        [-0.18402529],\n",
      "        [-0.18302155],\n",
      "        [-0.18232393],\n",
      "        [-0.18151236],\n",
      "        [-0.18061352],\n",
      "        [-0.17944098]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1836834 ],\n",
      "        [-0.184124  ],\n",
      "        [-0.1840086 ],\n",
      "        [-0.1837759 ],\n",
      "        [-0.18321896],\n",
      "        [-0.1825161 ],\n",
      "        [-0.18151855],\n",
      "        [-0.18049335],\n",
      "        [-0.17937946]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18350601],\n",
      "        [-0.18400002],\n",
      "        [-0.18401241],\n",
      "        [-0.18367052],\n",
      "        [-0.18323183],\n",
      "        [-0.18245602],\n",
      "        [-0.18151999],\n",
      "        [-0.18054199],\n",
      "        [-0.17925262]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18348408],\n",
      "        [-0.18394947],\n",
      "        [-0.18404007],\n",
      "        [-0.18384075],\n",
      "        [-0.18312216],\n",
      "        [-0.18263912],\n",
      "        [-0.18181229],\n",
      "        [-0.18068552],\n",
      "        [-0.17930603]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18349123],\n",
      "        [-0.18379498],\n",
      "        [-0.18365622],\n",
      "        [-0.18343687],\n",
      "        [-0.1831379 ],\n",
      "        [-0.18202877],\n",
      "        [-0.18102455],\n",
      "        [-0.17970562],\n",
      "        [-0.17862225]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18334341],\n",
      "        [-0.18384981],\n",
      "        [-0.18408394],\n",
      "        [-0.1835208 ],\n",
      "        [-0.18317986],\n",
      "        [-0.18235016],\n",
      "        [-0.18114328],\n",
      "        [-0.18011856],\n",
      "        [-0.17913103]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18348885],\n",
      "        [-0.18382359],\n",
      "        [-0.18413973],\n",
      "        [-0.18408012],\n",
      "        [-0.18345594],\n",
      "        [-0.18257427],\n",
      "        [-0.18174362],\n",
      "        [-0.18074608],\n",
      "        [-0.17953014]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18361759],\n",
      "        [-0.18395853],\n",
      "        [-0.18402958],\n",
      "        [-0.18379879],\n",
      "        [-0.18357992],\n",
      "        [-0.18255949],\n",
      "        [-0.18149424],\n",
      "        [-0.1804533 ],\n",
      "        [-0.17921066]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1836114 ],\n",
      "        [-0.18391037],\n",
      "        [-0.18419933],\n",
      "        [-0.1840682 ],\n",
      "        [-0.18358278],\n",
      "        [-0.18281221],\n",
      "        [-0.18168545],\n",
      "        [-0.18059301],\n",
      "        [-0.17910194]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1832695 ],\n",
      "        [-0.18365574],\n",
      "        [-0.18368435],\n",
      "        [-0.18309784],\n",
      "        [-0.18272972],\n",
      "        [-0.18190622],\n",
      "        [-0.18122196],\n",
      "        [-0.17996788],\n",
      "        [-0.17913294]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18341494],\n",
      "        [-0.18385696],\n",
      "        [-0.18357038],\n",
      "        [-0.18308878],\n",
      "        [-0.18256426],\n",
      "        [-0.18212795],\n",
      "        [-0.18135309],\n",
      "        [-0.18027973],\n",
      "        [-0.17913055]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18342876],\n",
      "        [-0.18384886],\n",
      "        [-0.18367767],\n",
      "        [-0.183496  ],\n",
      "        [-0.18296194],\n",
      "        [-0.18202257],\n",
      "        [-0.18129253],\n",
      "        [-0.18004227],\n",
      "        [-0.17899752]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18344784],\n",
      "        [-0.18383789],\n",
      "        [-0.1837492 ],\n",
      "        [-0.1837244 ],\n",
      "        [-0.18298864],\n",
      "        [-0.18172026],\n",
      "        [-0.18099546],\n",
      "        [-0.17997026],\n",
      "        [-0.17880201]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.183568  ],\n",
      "        [-0.18390656],\n",
      "        [-0.18383121],\n",
      "        [-0.1836958 ],\n",
      "        [-0.18261147],\n",
      "        [-0.18169641],\n",
      "        [-0.18097115],\n",
      "        [-0.18006325],\n",
      "        [-0.17888165]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18367052],\n",
      "        [-0.1842041 ],\n",
      "        [-0.18421459],\n",
      "        [-0.18386126],\n",
      "        [-0.18358135],\n",
      "        [-0.1826086 ],\n",
      "        [-0.1814084 ],\n",
      "        [-0.18024349],\n",
      "        [-0.17907429]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18380213],\n",
      "        [-0.18421221],\n",
      "        [-0.18459558],\n",
      "        [-0.18420887],\n",
      "        [-0.1835351 ],\n",
      "        [-0.18269777],\n",
      "        [-0.18191338],\n",
      "        [-0.18083525],\n",
      "        [-0.17941713]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18328094],\n",
      "        [-0.18366337],\n",
      "        [-0.18379307],\n",
      "        [-0.18344212],\n",
      "        [-0.18294287],\n",
      "        [-0.18196535],\n",
      "        [-0.18104935],\n",
      "        [-0.18046665],\n",
      "        [-0.17893505]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18361759],\n",
      "        [-0.18404579],\n",
      "        [-0.18380356],\n",
      "        [-0.18359709],\n",
      "        [-0.18299341],\n",
      "        [-0.18192196],\n",
      "        [-0.18124104],\n",
      "        [-0.17995787],\n",
      "        [-0.17870665]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18357992],\n",
      "        [-0.18368053],\n",
      "        [-0.1841917 ],\n",
      "        [-0.1836958 ],\n",
      "        [-0.18289661],\n",
      "        [-0.18203735],\n",
      "        [-0.18097353],\n",
      "        [-0.18003178],\n",
      "        [-0.17906237]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18373871],\n",
      "        [-0.18404388],\n",
      "        [-0.18418217],\n",
      "        [-0.18353033],\n",
      "        [-0.18276167],\n",
      "        [-0.18200207],\n",
      "        [-0.181005  ],\n",
      "        [-0.17972994],\n",
      "        [-0.17882872]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18337345],\n",
      "        [-0.18380642],\n",
      "        [-0.1838789 ],\n",
      "        [-0.18357182],\n",
      "        [-0.18325233],\n",
      "        [-0.18245697],\n",
      "        [-0.18125439],\n",
      "        [-0.18018913],\n",
      "        [-0.17911339]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1834178 ],\n",
      "        [-0.1838274 ],\n",
      "        [-0.18385029],\n",
      "        [-0.18391418],\n",
      "        [-0.18328857],\n",
      "        [-0.18239927],\n",
      "        [-0.1813364 ],\n",
      "        [-0.18037987],\n",
      "        [-0.17899084]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18339252],\n",
      "        [-0.1835084 ],\n",
      "        [-0.18376589],\n",
      "        [-0.18389416],\n",
      "        [-0.18338728],\n",
      "        [-0.18274021],\n",
      "        [-0.18146801],\n",
      "        [-0.18019962],\n",
      "        [-0.17911053]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18342733],\n",
      "        [-0.18377876],\n",
      "        [-0.18349886],\n",
      "        [-0.18337536],\n",
      "        [-0.18275547],\n",
      "        [-0.18230629],\n",
      "        [-0.18135309],\n",
      "        [-0.18014193],\n",
      "        [-0.17895699]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18346024],\n",
      "        [-0.18412542],\n",
      "        [-0.18423986],\n",
      "        [-0.18399763],\n",
      "        [-0.18318462],\n",
      "        [-0.18189192],\n",
      "        [-0.18098545],\n",
      "        [-0.18000841],\n",
      "        [-0.17877483]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18311977],\n",
      "        [-0.18370628],\n",
      "        [-0.18365908],\n",
      "        [-0.18318939],\n",
      "        [-0.1824069 ],\n",
      "        [-0.18123531],\n",
      "        [-0.18065405],\n",
      "        [-0.17968607],\n",
      "        [-0.17851782]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18325138],\n",
      "        [-0.18350983],\n",
      "        [-0.1835227 ],\n",
      "        [-0.18337631],\n",
      "        [-0.18286276],\n",
      "        [-0.18176985],\n",
      "        [-0.18060875],\n",
      "        [-0.17980051],\n",
      "        [-0.17853975]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18341732],\n",
      "        [-0.18378687],\n",
      "        [-0.18402386],\n",
      "        [-0.18391037],\n",
      "        [-0.1834178 ],\n",
      "        [-0.18237066],\n",
      "        [-0.18090057],\n",
      "        [-0.17980051],\n",
      "        [-0.17839384]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18351173],\n",
      "        [-0.18405485],\n",
      "        [-0.18432331],\n",
      "        [-0.18392944],\n",
      "        [-0.18303013],\n",
      "        [-0.18204308],\n",
      "        [-0.18090534],\n",
      "        [-0.17966843],\n",
      "        [-0.17843151]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18352604],\n",
      "        [-0.18415642],\n",
      "        [-0.18377209],\n",
      "        [-0.18350506],\n",
      "        [-0.18299866],\n",
      "        [-0.18222523],\n",
      "        [-0.18077469],\n",
      "        [-0.17954874],\n",
      "        [-0.17826939]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18334293],\n",
      "        [-0.18362427],\n",
      "        [-0.18374157],\n",
      "        [-0.18310738],\n",
      "        [-0.18234682],\n",
      "        [-0.18129349],\n",
      "        [-0.18042278],\n",
      "        [-0.1792469 ],\n",
      "        [-0.17769432]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1830759 ],\n",
      "        [-0.18342066],\n",
      "        [-0.18313837],\n",
      "        [-0.1827097 ],\n",
      "        [-0.1819396 ],\n",
      "        [-0.18084049],\n",
      "        [-0.1798315 ],\n",
      "        [-0.17882109],\n",
      "        [-0.17783642]]], dtype=float32)}, 'loss': 0.17395584, 'loss_err': 0.024953458349047188}, 'val': {'results': {'loss': array([0.02554345, 0.02554345, 0.02554345, 0.02554345, 0.02554345,\n",
      "       0.04521821, 0.02554345, 0.09505906, 0.39410073, 0.33515167],\n",
      "      dtype=float32), 'utility': array([-0.02513015, -0.02513015, -0.02513015, -0.02513015, -0.02513015,\n",
      "       -0.04480491, -0.02513015, -0.03707435, -0.31079143, -0.16919579],\n",
      "      dtype=float32), 'utility0': array([-0.0004133 , -0.0004133 , -0.0004133 , -0.0004133 , -0.0004133 ,\n",
      "       -0.0004133 , -0.0004133 , -0.05798471, -0.08330929, -0.1659559 ],\n",
      "      dtype=float32), 'gains': array([ 0.01077363, -0.02231139,  0.02417589, -0.00236187,  0.09563004,\n",
      "       -0.03496753,  0.08113132, -0.03110225, -0.1679608 , -0.09716297],\n",
      "      dtype=float32), 'payoff': array([-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "       -0.        , -0.        , -0.02878571, -0.041448  , -0.0827713 ],\n",
      "      dtype=float32), 'pnl': array([ 0.01124313, -0.02184682,  0.0246506 , -0.00188951,  0.0961217 ,\n",
      "       -0.03450039,  0.08162129, -0.00183709, -0.12605514, -0.01390504],\n",
      "      dtype=float32), 'cost': array([0.00046949, 0.00046457, 0.00047471, 0.00047236, 0.00049166,\n",
      "       0.00046714, 0.00048997, 0.00047945, 0.00045767, 0.00048663],\n",
      "      dtype=float32), 'actions': array([[[ 0.7306366 ],\n",
      "        [-0.18343067],\n",
      "        [-0.18406677],\n",
      "        [-0.1842289 ],\n",
      "        [-0.18394089],\n",
      "        [-0.18349648],\n",
      "        [-0.18270588],\n",
      "        [-0.18178844],\n",
      "        [-0.18067265],\n",
      "        [-0.17971611]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18348408],\n",
      "        [-0.18414736],\n",
      "        [-0.18445015],\n",
      "        [-0.18409824],\n",
      "        [-0.183568  ],\n",
      "        [-0.18275833],\n",
      "        [-0.18179178],\n",
      "        [-0.18069553],\n",
      "        [-0.17983913]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18346596],\n",
      "        [-0.18392467],\n",
      "        [-0.18384552],\n",
      "        [-0.18375397],\n",
      "        [-0.18322182],\n",
      "        [-0.18275547],\n",
      "        [-0.18190336],\n",
      "        [-0.18079996],\n",
      "        [-0.17957783]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18362236],\n",
      "        [-0.18399954],\n",
      "        [-0.18395424],\n",
      "        [-0.18392086],\n",
      "        [-0.18352985],\n",
      "        [-0.18267632],\n",
      "        [-0.18172455],\n",
      "        [-0.18060923],\n",
      "        [-0.17948103]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18335724],\n",
      "        [-0.18379307],\n",
      "        [-0.1841445 ],\n",
      "        [-0.18350887],\n",
      "        [-0.182796  ],\n",
      "        [-0.18209743],\n",
      "        [-0.18108654],\n",
      "        [-0.18011856],\n",
      "        [-0.17925835]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.1835165 ],\n",
      "        [-0.18402386],\n",
      "        [-0.18431187],\n",
      "        [-0.18406487],\n",
      "        [-0.18360853],\n",
      "        [-0.1826644 ],\n",
      "        [-0.18181038],\n",
      "        [-0.18072987],\n",
      "        [-0.17967892]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18321133],\n",
      "        [-0.18358135],\n",
      "        [-0.18330574],\n",
      "        [-0.18327475],\n",
      "        [-0.18277216],\n",
      "        [-0.18220139],\n",
      "        [-0.18167543],\n",
      "        [-0.1809907 ],\n",
      "        [-0.17986107]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18385172],\n",
      "        [-0.18410683],\n",
      "        [-0.18413067],\n",
      "        [-0.1836276 ],\n",
      "        [-0.18301964],\n",
      "        [-0.18204641],\n",
      "        [-0.18134499],\n",
      "        [-0.1805811 ],\n",
      "        [-0.17951727]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18362713],\n",
      "        [-0.18408346],\n",
      "        [-0.18453312],\n",
      "        [-0.18449354],\n",
      "        [-0.18401098],\n",
      "        [-0.18315506],\n",
      "        [-0.18184137],\n",
      "        [-0.18069506],\n",
      "        [-0.1793747 ]],\n",
      "\n",
      "       [[ 0.7306366 ],\n",
      "        [-0.18330956],\n",
      "        [-0.18371964],\n",
      "        [-0.18387318],\n",
      "        [-0.18381023],\n",
      "        [-0.1831398 ],\n",
      "        [-0.18253517],\n",
      "        [-0.18148232],\n",
      "        [-0.18030119],\n",
      "        [-0.17886734]]], dtype=float32)}, 'loss': 0.102279045, 'loss_err': 0.04219333246321426}, 'display_name': 'VanillaDeepHedging', 'progress_data': <deephedging.trainer2.TrainingProgressData object at 0x000002CCA5955C60>, 'gym': <deephedging.gym2.VanillaDeepHedgingGym object at 0x000002CCFE7A95D0>, 'start_time': datetime.datetime(2023, 3, 26, 23, 50, 42, 178693), 'end_time': datetime.datetime(2023, 3, 26, 23, 51, 8, 139763), 'epochs_trained': 12, 'stop_reason': <Status.FINISHED_EPOCHS: 1>, 'stop_exception': None}\n",
      "=========================================\n",
      "Config usage report\n",
      "config.gym.agent['activation'] = softplus # Activation function; default: relu\n",
      "config.gym.agent['depth'] = 3 # Depth; default: 3\n",
      "config.gym.agent['features'] = ['price', 'time_left', 'delta'] # Names of features to be used by this agent; default: ['price', 'time_left', 'delta']\n",
      "config.gym.agent['final_activation'] = linear # Final activation function; default: linear\n",
      "config.gym.agent['recurrence'] = 5 # Number of recurrent nodes; default: 5\n",
      "config.gym.agent['simple_regression'] = False # Learn simple regression model only; default: False\n",
      "config.gym.agent['width'] = 10 # Width; default: 50\n",
      "config.gym.agent['zero_model'] = True # Whether to initialze levels (but not derivatives) of the model with zero; default: True\n",
      "config.gym.environment['hard_clip'] = False # Use min/max instread of soft clip for limiting actions by their bounds; default: False\n",
      "config.gym.environment['outer_clip'] = True # Apply a hard clip 'outer_clip_cut_off' times the boundaries; default: True\n",
      "config.gym.environment['outer_clip_cut_off'] = 10.0 # Multiplier on bounds for outer_clip; default: 10.0\n",
      "config.gym.environment['softclip_hinge_softness'] = 1.0 # Specifies softness of bounding actions between lbnd_a and ubnd_a; default: 1.0\n",
      "config.gym.init_agent['activation'] = softplus # Activation function; default: relu\n",
      "config.gym.init_agent['depth'] = 2 # Depth; default: 3\n",
      "config.gym.init_agent['features'] = ['price'] # Names of features to be used by this agent; default: ['price']\n",
      "config.gym.init_agent['final_activation'] = linear # Final activation function; default: linear\n",
      "config.gym.init_agent['simple_regression'] = False # Learn simple regression model only; default: False\n",
      "config.gym.init_agent['width'] = 10 # Width; default: 25\n",
      "config.gym.init_agent['zero_model'] = True # Whether to initialze levels (but not derivatives) of the model with zero; default: True\n",
      "config.gym.objective['activation'] = softplus # Activation function; default: relu\n",
      "config.gym.objective['depth'] = 2 # Depth; default: 3\n",
      "config.gym.objective['features'] = ['price'] # Names of features to be used by this agent; default: ['price']\n",
      "config.gym.objective['final_activation'] = linear # Final activation function; default: linear\n",
      "config.gym.objective['lmbda'] = 1.0 # Risk aversion; default: 1.0\n",
      "config.gym.objective['simple_regression'] = False # Learn simple regression model only; default: False\n",
      "config.gym.objective['utility'] = cvar # Type of monetary utility; default: exp2\n",
      "config.gym.objective['width'] = 10 # Width; default: 25\n",
      "config.gym.objective['zero_model'] = True # Whether to initialze levels (but not derivatives) of the model with zero; default: True\n",
      "config.gym.tensorflow['seed'] = 423423423 # Set tensor random seed. Leave to None if not desired; default: 423423423\n",
      "config.gym['user_version'] = 0.0.1 # User-defined version of a gym. Changing this string will change the cache ID, and therefore will trigger a new calculation; default: 0.0.1\n",
      "config.trainer.caching['directory'] = ./.cache # Caching parent directory; default: ./.cache\n",
      "config.trainer.caching['epoch_freq'] = 10 # How often to cache results, in number of epochs; default: 10\n",
      "config.trainer.caching['mode'] = off # Caching strategy: 'on' for standard caching; 'gen' for caching but keep existing incompatible files; 'off' to turn off; 'update' to overwrite any existing cache; 'clear' to clear existing caches; 'readonly' to read existing caches but not write new ones; default: on\n",
      "config.trainer.caching['overwrite_file_name'] =  # Allows overwriting the full qualified filename of the object\n",
      "config.trainer.debug['check_numerics'] = False # Whether to check TF numerics; default: False\n",
      "config.trainer.debug['tf_verbose'] = 0 # Verbosity for TensorFlow fit(); default: 0\n",
      "config.trainer.train.optimizer['amsgrad'] = False # Parameter amsgrad for <class 'keras.optimizers.adam.Adam'>; default: False\n",
      "config.trainer.train.optimizer['beta_1'] = 0.9 # Parameter beta_1 for <class 'keras.optimizers.adam.Adam'>; default: 0.9\n",
      "config.trainer.train.optimizer['beta_2'] = 0.999 # Parameter beta_2 for <class 'keras.optimizers.adam.Adam'>; default: 0.999\n",
      "config.trainer.train.optimizer['clipnorm'] = None # Parameter clipnorm for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['clipvalue'] = 1.0 # Parameter clipvalue for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['ema_momentum'] = 0.99 # Parameter ema_momentum for <class 'keras.optimizers.adam.Adam'>; default: 0.99\n",
      "config.trainer.train.optimizer['ema_overwrite_frequency'] = None # Parameter ema_overwrite_frequency for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['epsilon'] = 1e-07 # Parameter epsilon for <class 'keras.optimizers.adam.Adam'>; default: 1e-07\n",
      "config.trainer.train.optimizer['global_clipnorm'] = 1.0 # Parameter global_clipnorm for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.optimizer['jit_compile'] = True # Parameter jit_compile for <class 'keras.optimizers.adam.Adam'>; default: True\n",
      "config.trainer.train.optimizer['learning_rate'] = 0.001 # Parameter learning_rate for <class 'keras.optimizers.adam.Adam'>; default: 0.001\n",
      "config.trainer.train.optimizer['name'] = adam # Optimizer name. See https://www.tensorflow.org/api_docs/python/tf/keras/optimizers; default: adam\n",
      "config.trainer.train.optimizer['use_ema'] = False # Parameter use_ema for <class 'keras.optimizers.adam.Adam'>; default: False\n",
      "config.trainer.train.optimizer['weight_decay'] = None # Parameter weight_decay for <class 'keras.optimizers.adam.Adam'>; default: None\n",
      "config.trainer.train.tensor_board['hist_freq'] = 1 # Specify tensor board log frequency. See https://www.tensorflow.org/guide/profiler; default: 1\n",
      "config.trainer.train.tensor_board['log_dir'] =  # Specify tensor board log directory. See https://www.tensorflow.org/guide/profiler\n",
      "config.trainer.train.tensor_board['profile_batch'] = 0 # Batch used for profiling. Set to non-zero to activate profiling. See https://www.tensorflow.org/guide/profiler; default: 0\n",
      "config.trainer.train['batch_size'] = None # Batch size; default: None\n",
      "config.trainer.train['display_name'] = VanillaDeepHedging # Display name for this training run; default: VanillaDeepHedging\n",
      "config.trainer.train['epochs'] = 12 # Epochs; default: 100\n",
      "config.trainer.train['run_eagerly'] = False # Keras gym run_eagerly. Turn to True for debugging. This slows down training. Use None for default; default: False\n",
      "config.world['black_scholes'] = True # Hard overwrite to use a black & scholes model with vol 'rvol' and drift 'drift'. Also turns off the option as a tradable instrument by setting strike = 0; default: False\n",
      "config.world['corr_ms'] = 0.5 # Correlation between the asset and its mean; default: 0.5\n",
      "config.world['corr_vi'] = 0.8 # Correlation between the implied vol and the asset volatility; default: 0.8\n",
      "config.world['corr_vs'] = -0.7 # Correlation between the asset and its volatility; default: -0.7\n",
      "config.world['cost_p'] = 0.0005 # Trading cost for the option on top of delta and vega cost; default: 0.0005\n",
      "config.world['cost_s'] = 0.0002 # Trading cost spot; default: 0.0002\n",
      "config.world['cost_v'] = 0.02 # Trading cost vega; default: 0.02\n",
      "config.world['drift'] = 0.1 # Mean drift of the asset. This is the total drift; default: 0.1\n",
      "config.world['drift_vol'] = 0.1 # Vol of the drift; default: 0.1\n",
      "config.world['dt'] = 0.02 # Time per timestep; default: One week (1/50)\n",
      "config.world['invar_steps'] = 5 # Number of steps ahead to sample from invariant distribution; default: 5\n",
      "config.world['ivol'] = 0.2 # Initial implied volatility; default: Same as realized vol\n",
      "config.world['lbnd_as'] = -5.0 # Lower bound for the number of shares traded at each time step; default: -5.0\n",
      "config.world['lbnd_av'] = -5.0 # Lower bound for the number of options traded at each time step; default: -5.0\n",
      "config.world['meanrev_drift'] = 1.0 # Mean reversion of the drift of the asset; default: 1.0\n",
      "config.world['meanrev_ivol'] = 0.1 # Mean reversion for implied vol vol vs initial level; default: 0.1\n",
      "config.world['meanrev_rvol'] = 2.0 # Mean reversion for realized vol vs implied vol; default: 2.0\n",
      "config.world['no_stoch_drift'] = False # If true, turns off the stochastic drift of the asset, by setting meanrev_drift = 0. and drift_vol = 0; default: False\n",
      "config.world['no_stoch_vol'] = False # If true, turns off stochastic realized and implied vol, by setting meanrev_*vol = 0 and volvol_*vol = 0; default: False\n",
      "config.world['payoff'] = atmcall # Payoff function with parameter spots[samples,steps+1]. Can be a function which must return a vector [samples]. Can also be short 'atmcall' or short 'atmput', or a fixed numnber. The default is 'atmcall' which is a short call with strike 1: '- np.maximum( spots[:,-1] - 1, 0. )'. A short forward starting ATM call is given as '- np.maximum( spots[:,-1] - spots[:,0], 0. )'; default: atmcall\n",
      "config.world['rcorr_vs'] = -0.5 # Residual correlation between the asset and its implied volatility; default: -0.5\n",
      "config.world['rvol'] = 0.2 # Initial realized volatility; default: 0.2\n",
      "config.world['samples'] = 100 # Number of samples; default: 1000\n",
      "config.world['seed'] = 2312414312 # Random seed; default: 2312414312\n",
      "config.world['steps'] = 10 # Number of time steps; default: 10\n",
      "config.world['strike'] = 1.0 # Relative strike. Set to zero to turn off option; default: 1.0\n",
      "config.world['ttm_steps'] = 4 # Time to maturity of the option; in steps; default: 4\n",
      "config.world['ubnd_as'] = 5.0 # Upper bound for the number of shares traded at each time step; default: 5.0\n",
      "config.world['ubnd_av'] = 5.0 # Upper bound for the number of options traded at each time step; default: 5.0\n",
      "config.world['volvol_ivol'] = 0.5 # Vol of Vol for implied vol; default: 0.5\n",
      "config.world['volvol_rvol'] = 0.5 # Vol of Vol for realized vol; default: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Hedging AI says hello ... \")\n",
    "\n",
    "import importlib as imp\n",
    "import packages.cdx_tf.cdx_tf.gym as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.clip as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.optimizer as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.layers as _\n",
    "imp.reload(_)\n",
    "import packages.cdx_tf.cdx_tf.monetary_utility as _\n",
    "imp.reload(_)\n",
    "\n",
    "import deephedging.gym2 as _\n",
    "imp.reload(_)\n",
    "import deephedging.trainer2 as _\n",
    "imp.reload(_)\n",
    "\n",
    "from cdxbasics.config import Config\n",
    "from deephedging.trainer2 import train2\n",
    "from deephedging.gym2 import VanillaDeepHedgingGym\n",
    "from deephedging.world import SimpleWorld_Spot_ATM\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# see print of the config below for numerous options\n",
    "config = Config()\n",
    "# world\n",
    "config.world.samples = 100\n",
    "config.world.black_scholes = True\n",
    "# gym\n",
    "config.gym.objective.utility = \"cvar\"\n",
    "config.gym.objective.lmbda = 1.\n",
    "config.gym.objective.depth = 2\n",
    "config.gym.objective.width = 10\n",
    "config.gym.objective.activation = \"softplus\"\n",
    "config.gym.agent.depth = 3\n",
    "config.gym.agent.width = 10\n",
    "config.gym.agent.activation = \"softplus\"\n",
    "config.gym.init_agent.depth = 2\n",
    "config.gym.init_agent.width = 10\n",
    "config.gym.init_agent.activation = \"softplus\"\n",
    "# trainer\n",
    "config.trainer.train.optimizer.name = \"adam\"\n",
    "config.trainer.train.optimizer.learning_rate = 0.001\n",
    "config.trainer.train.optimizer.clipvalue = 1.\n",
    "config.trainer.train.optimizer.global_clipnorm = 1.\n",
    "config.trainer.train.batch_size = None\n",
    "config.trainer.train.epochs = 12\n",
    "config.trainer.caching.mode = \"off\"\n",
    "\"\"\"\n",
    "config.trainer.visual.epoch_refresh = 5\n",
    "config.trainer.visual.confidence_pcnt_lo = 0.25\n",
    "config.trainer.visual.confidence_pcnt_hi = 0.75\n",
    "\"\"\"\n",
    "# create world\n",
    "world  = SimpleWorld_Spot_ATM( config.world )\n",
    "val_world  = world.clone(samples=world.nSamples//10)\n",
    "\n",
    "r = train2( world     = world,\n",
    "            val_world = val_world,\n",
    "            config    = config )\n",
    "\n",
    "\n",
    "# create training environment\n",
    "print(\"=========================================\")\n",
    "print(\"Result\")\n",
    "print(r)\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"Config usage report\")\n",
    "print( config.usage_report() )\n",
    "config.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba112b-167c-4752-bd16-3bb8ca56eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.DType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7422005-dd4b-45c0-a305-8522b3e3ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.dtypes.DType('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6acff-5594-4d8f-a474-6e631b9236e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type( tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44f533-ac90-4b22-860c-daee6876f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.dtypes.as_dtype(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc07da53-545b-4852-a87e-0f3a5b1e8bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config.x'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Config()\n",
    "c.x.y = 1\n",
    "c.x.config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff6c287-8ec8-4e6a-b840-6df48cd781e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config.x'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = config.x.detach()\n",
    "x.config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d0dc3-58c1-4b13-9cdf-4dd05feb7a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
